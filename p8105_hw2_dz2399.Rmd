---
title: "p8105_hw1_dz2399"
author: "DZ"
date: "September 29, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)
```

## Problem 1

### Read in the data according to instuctions
```{r}
df_nyc <- read_csv(file='./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>%
  janitor::clean_names() %>%
  select(line, starts_with('station'),starts_with('route'),entry, vending,ada,entrance_type) %>% 
  select(-station_location) %>% 
  mutate(entry = recode (entry, 'YES' = T, 'NO'=F))

dim(df_nyc)
```

 The dataset contains the following variables: line, station_name, station longitute and latitude, the route that the train serves, entry and entry types, vending, and ada. The data cleaning process is that: firstly, read in the data from the directory and conduct a column-name-cleaning with the function clean_names; then, select the desired variables; lastly, recode the entry variable with yes equals to T and no to F. The dimension of the resulting dataset is `r dim(df_nyc)`. This is not a tidy data, because the route variables are spreadout to multiple columns rather than a single column.

#### How many distinct stations are there?
```{r}
dim(distinct(df_nyc, station_name))[1]
```
There are 356 distinct stations in the dataset.

#### How many stations are ADA compliant?
```{r}
df_nyc %>% 
  filter(ada==T) %>% 
  distinct(station_name) %>% 
  dim()
```
There are 73 stations that are ADA compliant in the dataset.

#### What proportion of station entrances / exits without vending allow entrance?
```{r}
dim(df_nyc %>% filter(vending=='NO'))[1]/dim(df_nyc)[1]
```
Among all entrancss/ exits  in the dataset, 9.7% of the entrance/exit do not have vending machines.

#### How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?
```{r}
df_nyc %>% 
  gather(key=route_number, value=route_name,route1:route11) %>% 
  filter(route_name=='A') %>% 
  distinct(station_name) %>% 
  dim()

df_nyc %>% 
  gather(key=route_number, value=route_name,route1:route11) %>% 
  filter(route_name=='A',ada==T) %>% 
  distinct(station_name) %>% 
  dim()
```
Therefore, 56 stations serves the A train in the dataset, and of those 56 stations, 16 stations are APA compliant. 

## Problem 2

#### Read and clean the Mr. Trash Wheel sheet:

* specify the sheet in the Excel file and to omit columns containing notes (using the range argument and  cell_cols() function)
* use reasonable variable names
* omit rows that do not include dumpster-specific data
* rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using  as.integer)

```{r}
df_tw <- readxl::read_excel('./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx',range='A2:N258') %>% 
  janitor::clean_names() %>% 
  filter(!dumpster=='NA') %>% 
  mutate(sports_balls = as.integer(round(sports_balls,0)))
```

#### Read and clean precipitation data for 2016 and 2017. 
For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).
```{r}
precip_2017 <- readxl::read_excel('./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx',
                                 sheet=3, range = 'A2:B15') %>% 
  mutate(year= rep(2017,13)) %>% 
  filter(!Total=='NA',!Month=='NA')

precip_2016 <- readxl::read_excel('./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx',
                                 sheet=4, range = 'A2:B15') %>% 
  mutate(year= rep(2016,13)) %>% 
  filter(!Total=='NA',!Month=='NA')

precip_full <- rbind(precip_2016,precip_2017) %>% 
  mutate(Month = as.factor(Month))
levels(precip_full$Month) <- month.name
precip_full
```

The resulting 2017 precipitation data has the dimension of `r dim(precip_2017)`, and the resulting 2016 precipitation data has the dimension of `r dim(precip_2016)`
Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

## Problem 3
For this question:

format the data to use appropriate variable names;
focus on the “Overall Health” topic
exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
structure data so that responses (excellent to poor) are variables taking the value of Data_value
create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
```{r}
data("brfss_smart2010")
df_brfss <- brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == 'Overall Health') %>% 
  select(-c(class,topic,question,sample_size,confidence_limit_low:geo_location)) %>%
  spread(key=response, value=data_value)
  
  
```

